{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-3 Product Dissemination Unit Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Version: 2.0\n",
    "    Date:    17/09/2019\n",
    "    Author:  Ben Loveday (Plymouth Marine Laboratory ) and Hayley Evers-King (EUMETSAT)\n",
    "    Credit:  This code was developed for EUMETSAT under contracts for the Copernicus \n",
    "             programme.\n",
    "    License: This code is offered as open source and free-to-use in the public domain, \n",
    "             with no warranty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows you the spatial extent of Sentinel-3 Level-1B and Level-2 NRT and NTC products from three different sensors (OLCI, SLSTR and SRAL). **To run this script, you will need to have your key for the harmonised data access API.** You can get your key from here; https://www.wekeo.eu/api-keys. If you click on the 'show hidden keys' button at the bottom of the page it will reveal a number of keys. The one you need is in the top grey box, and is on the following line:\n",
    "\n",
    "-H \"Authorization: Basic \"**YOUR API KEY**\"\n",
    "\n",
    "Replace \"YOUR API KEY\" below with what you copy from \"**YOUR API KEY**\" (N.B. you need to keep the quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# libraries are imported here, and we can import any library with an alias that allows us easy access to them later.\n",
    "import os, sys\n",
    "import xarray as xr\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import warnings\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.patches as mpatches\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/Hub_Tools/')\n",
    "import harmonised_data_access_api_tools as hapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the harmonised data API so we can download data to the Jupyter hub workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"cmJ1UGJQVzZnT09HU2RUWDJhTGFkOGY4RjhnYTpGRmFCTTNoSXluVk1NdEk4b2dPc2ZjMHFOdlVh\"\n",
    "download_dir_path = \"/home/jovyan/work/products\"\n",
    "JSON_query_dir = os.path.join(os.getcwd(),'JSON_templates')\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = []\n",
    "file_types = []\n",
    "# OLCI REDUCED RESOLUTION L2 FILE\n",
    "dataset_ids.append(\"EO:EUM:DAT:SENTINEL-3:OL_2_WRR___\")\n",
    "file_types.append('WRR')\n",
    "\n",
    "# OLCI FULL RESOLUTION L2 FILE\n",
    "dataset_ids.append(\"EO:EUM:DAT:SENTINEL-3:OL_2_WFR___\")\n",
    "file_types.append('WFR')\n",
    "\n",
    "# SLSTR L1 FILE\n",
    "dataset_ids.append(\"EO:EUM:DAT:SENTINEL-3:SL_1_RBT___\")\n",
    "file_types.append('RBT')\n",
    "\n",
    "# SLSTR L2 FILE\n",
    "dataset_ids.append(\"EO:EUM:DAT:SENTINEL-3:SL_2_WST___\")\n",
    "file_types.append('WST')\n",
    "\n",
    "# SRAL L2 FILE\n",
    "dataset_ids.append(\"EO:EUM:DAT:SENTINEL-3:SR_2_WAT___\")\n",
    "file_types.append('WAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find query file\n",
    "JSON_query_files = []\n",
    "for dataset_id in dataset_ids:\n",
    "    JSON_query_file = os.path.join(JSON_query_dir,dataset_id.replace(':','_')+\".json\")\n",
    "    if not os.path.exists(JSON_query_file):\n",
    "        print('Query file ' + JSON_query_file + ' does not exist')\n",
    "    else:\n",
    "        print('Found JSON query file for '+dataset_id)\n",
    "    JSON_query_files.append(JSON_query_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "downloaded_files = []\n",
    "for dataset_id,JSON_query_file in zip(dataset_ids, JSON_query_files):\n",
    "\n",
    "    HAPI_dict = hapi.init(dataset_id, api_key, download_dir_path, verbose=verbose)\n",
    "    HAPI_dict = hapi.get_access_token(HAPI_dict)\n",
    "    HAPI_dict = hapi.accept_TandC(HAPI_dict)\n",
    "\n",
    "    # load the query\n",
    "    with open(JSON_query_file, 'r') as f:\n",
    "        query = json.load(f)\n",
    "\n",
    "    # launch job\n",
    "    HAPI_dict = hapi.launch_query(HAPI_dict, query)\n",
    "\n",
    "    # wait for jobs to complete\n",
    "    hapi.check_job_status(HAPI_dict)\n",
    "\n",
    "    # check results\n",
    "    HAPI_dict = hapi.get_results_list(HAPI_dict)\n",
    "    HAPI_dict = hapi.get_download_links(HAPI_dict)\n",
    "\n",
    "    t0 = time.time()\n",
    "    # download data\n",
    "    HAPI_dict = hapi.download_data(HAPI_dict, skip_existing=True)\n",
    "\n",
    "    # unzip file\n",
    "    for filename in HAPI_dict['filenames']:\n",
    "        downloaded_files.append(filename)\n",
    "        if os.path.splitext(filename)[-1] == '.zip':\n",
    "            print('Unzipping file')\n",
    "            with ZipFile(filename, 'r') as zipObj:\n",
    "                # Extract all the contents of zip file in current directory\n",
    "                zipObj.extractall(os.path.dirname(filename))\n",
    "                \n",
    "    # flush benchmark timing to stdout print\n",
    "    print(' ')\n",
    "    print('--------------------------------')\n",
    "    print('Elapsed time: ' +str(time.time() - t0))\n",
    "    print('--------------------------------')\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel-3 products from each sensor are delivered with different product dissemination units with different coverage. The files below will be used to make a plot that show all of the coverage options for each sensor and product, for a given timeliness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load in the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for downloaded_file, file_type in zip(downloaded_files, file_types):\n",
    "    unzipped_file = downloaded_file.replace('.zip','.SEN3')\n",
    "    if file_type == 'WRR':\n",
    "        # OLCI REDUCED RESOLUTION --------------------------\n",
    "        ds1 = xr.open_dataset(os.path.join(unzipped_file, 'geo_coordinates.nc'))\n",
    "        OLCI_RR_LAT = ds1.latitude\n",
    "        OLCI_RR_LON = ds1.longitude\n",
    "        ds1.close()\n",
    "    elif file_type == 'WFR':\n",
    "        # OLCI FULL RESOLUTION --------------------------\n",
    "        ds1 = xr.open_dataset(os.path.join(unzipped_file, 'geo_coordinates.nc'))\n",
    "        OLCI_FR_LAT = ds1.latitude\n",
    "        OLCI_FR_LON = ds1.longitude\n",
    "        ds1.close()\n",
    "    elif file_type == 'RBT':\n",
    "        # SLSTR NADIR L1  --------------------------\n",
    "        ds1 = xr.open_dataset(os.path.join(unzipped_file, 'geodetic_in.nc'))\n",
    "        SLSTR_L1_LAT_N = ds1.latitude_in\n",
    "        SLSTR_L1_LON_N = ds1.longitude_in\n",
    "        ds1.close()\n",
    "        # SLSTR OBLIQUE L1  --------------------------\n",
    "        ds1 = xr.open_dataset(os.path.join(unzipped_file, 'geodetic_io.nc'))\n",
    "        SLSTR_L1_LAT_O = ds1.latitude_io\n",
    "        SLSTR_L1_LON_O = ds1.longitude_io\n",
    "        ds1.close()\n",
    "    elif file_type == 'WST':\n",
    "        sub_file = glob.glob(os.path.join(unzipped_file, '*.nc'))[0]\n",
    "        # SLSTR L2  --------------------------\n",
    "        ds1 = xr.open_dataset(sub_file)\n",
    "        SLSTR_L2_LAT = ds1.lat\n",
    "        SLSTR_L2_LON = ds1.lon\n",
    "        SLSTR_L2_ALG = np.squeeze(ds1.sst_algorithm_type)\n",
    "        SLSTR_L2_LON_D = SLSTR_L2_LON.copy().values\n",
    "        SLSTR_L2_LON_D[SLSTR_L2_ALG.values<3] = np.nan\n",
    "        ds1.close()\n",
    "    elif file_type == 'WAT':\n",
    "        # SRAL L2  --------------------------\n",
    "        ds1 = xr.open_dataset(os.path.join(unzipped_file, 'standard_measurement.nc'))\n",
    "        SRAL_L2_LAT = ds1.lat_20_ku\n",
    "        SRAL_L2_LON = ds1.lon_20_ku\n",
    "        ds1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLSTR data is full orbit, which is hard to plot. We will manipulate it slightly near the date line to make our plots better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove international date line edges to stop bad interpolation\n",
    "SLSTR_L2_COL = np.ones(np.shape(SLSTR_L2_LON))\n",
    "SLSTR_L2_COL_D = np.ones(np.shape(SLSTR_L2_LON_D))\n",
    "SLSTR_L2_COL[SLSTR_L2_LON < -179.0] = np.nan\n",
    "SLSTR_L2_COL[SLSTR_L2_LON > 179.0] = np.nan\n",
    "SLSTR_L2_COL_D[SLSTR_L2_LON_D < -179.0] = np.nan\n",
    "SLSTR_L2_COL_D[SLSTR_L2_LON_D > 179.0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coastline data we need for our map plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_resolution = '50m'\n",
    "land_poly = cfeature.NaturalEarthFeature('physical', 'land', land_resolution,\n",
    "                                        edgecolor='k',\n",
    "                                        facecolor=cfeature.COLORS['land'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the data. This may take a little bit of time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(20, 40), dpi=300)\n",
    "\n",
    "gs  = gridspec.GridSpec(2, 1)\n",
    "\n",
    "#---\n",
    "# plot dumps/stripes\n",
    "m = plt.subplot(gs[0,0], projection = ccrs.PlateCarree(central_longitude=0.0))\n",
    "levels = [0.0, 1.0]\n",
    "f1 = m.contourf(OLCI_RR_LON, OLCI_RR_LAT, OLCI_RR_LAT*0.0+1.0, levels, colors=('#A2CD5A'), zorder=10, alpha=0.75)\n",
    "f2 = m.plot(SRAL_L2_LON, SRAL_L2_LAT, marker='o', linewidth=0.0, color='b', zorder=14, markersize=2)\n",
    "f3 = m.contourf(SLSTR_L2_LON, SLSTR_L2_LAT, SLSTR_L2_COL, levels, colors=('#FFB90F'), zorder=12, alpha=0.75)\n",
    "\n",
    "m.coastlines(resolution=land_resolution, color='black', linewidth=1, zorder=1)\n",
    "m.add_feature(land_poly, zorder=0)\n",
    "g1 = m.gridlines(draw_labels = True)\n",
    "g1.xlabels_top = False\n",
    "g1.ylabels_right = False\n",
    "g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "plt.title('Sentinel-3 Product coverage: dumps', fontsize=20)\n",
    "\n",
    "patch1 = mpatches.Patch(facecolor='#A2CD5A', edgecolor='k', label='OLCI RR L1 & L2 (NRT & NTC)')\n",
    "patch2 = mpatches.Patch(facecolor='#FFB90F', edgecolor='k', label='SLSTR NADIR L2 NTC')\n",
    "patch3 = mpatches.Patch(facecolor='b',       edgecolor='k', label='SRAL L1 & L2 (NRT & NTC)')\n",
    "plt.legend(loc=9, bbox_to_anchor=(0.5, -0.1), handles=[patch1, patch2, patch3], fontsize=16)\n",
    "\n",
    "# ---\n",
    "# plot frames/granules\n",
    "m = plt.subplot(gs[1,0], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "levels = [0.0, 1.0]\n",
    "f1 = m.contourf(OLCI_FR_LON, OLCI_FR_LAT, OLCI_FR_LAT*0.0+1.0, levels, colors=('#556B2F'), zorder=12,\\\n",
    "                alpha=1.0, hatches=['/'])\n",
    "f2 = m.contourf(SLSTR_L1_LON_O, SLSTR_L1_LAT_O, SLSTR_L1_LAT_O*0.0+1.0, levels, colors=('#FFB90F'),\\\n",
    "                zorder=13, alpha=0.9)\n",
    "f3 = m.contourf(SLSTR_L1_LON_N, SLSTR_L1_LAT_N, SLSTR_L1_LAT_N*0.0+1.0, levels, colors=('b'),\\\n",
    "                zorder=11, alpha=0.8)\n",
    "\n",
    "m.coastlines(resolution=land_resolution, color='black', linewidth=1, zorder=1)\n",
    "m.add_feature(land_poly, zorder=0)\n",
    "g1 = m.gridlines(draw_labels = True)\n",
    "g1.xlabels_top = False\n",
    "g1.ylabels_right = False\n",
    "g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "plt.title('Sentinel-3 Product coverage: frames', fontsize=20)\n",
    "patch1 = mpatches.Patch(facecolor='b',       edgecolor='k', label='SLSTR NADIR L1 (NRT & NTC) and L2 (NRT)')\n",
    "patch2 = mpatches.Patch(facecolor='#A2CD5A', edgecolor='k', label='OLCI FR L1 & L2 (NRT & NTC)', hatch='///')\n",
    "patch3 = mpatches.Patch(facecolor='#FFB90F', edgecolor='k', label='SLSTR  L1 DUAL/OBLIQUE (NRT & NTC) and L2 (NRT)')\n",
    "plt.legend(loc=9, bbox_to_anchor=(0.5, -0.1), handles=[patch1, patch2, patch3], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
