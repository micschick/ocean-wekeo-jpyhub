{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMEMS OSTIA REP Data Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Version: 1.0\n",
    "    Date:    27/09/2019\n",
    "    Author:  Ben Loveday (Plymouth Marine Laboratory) and Hayley Evers-King (EUMETSAT)\n",
    "    Credit:  This code was developed for EUMETSAT under contracts for the Copernicus \n",
    "             programme.\n",
    "    License: This code is offered as open source and free-to-use in the public domain, \n",
    "             with no warranty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is this notebook for?**\n",
    "\n",
    "This notebook will download CMEMS OSTIA REP (RAN) data to support marine heat wave calculations.\n",
    "\n",
    "**What specific tools does this notebook use?**\n",
    "\n",
    "The harmonised data access API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is divided into a series of modules that each contain a series of methods for specific tasks. The box below imports all of the modules we need to complete this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard tools\n",
    "import os, sys, json\n",
    "\n",
    "# specific tools (which can be found here ../../Hub_tools/)\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())) + '/Hub_Tools/')\n",
    "import harmonised_data_access_api_tools as hapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEkEO provides access to a huge number of datasets through its 'harmonised-data-access' API. This allows us to query the full data catalogue and download data quickly and directly onto our Jupyter Hub. You can search for what data is available here: https://www.wekeo.eu/dataset-navigator/start.\n",
    "\n",
    "In order to use the HDA-API we need to provide some authentication credentials, which comes in the form of an api_key. You can get your key from here; https://www.wekeo.eu/api-keys. If you click on the 'show hidden keys' button at the bottom of the page it will reveal a number of keys. The one you need is in the top grey box, and is on the following line:\n",
    "\n",
    "-H \"Authorization: Basic \"**YOUR API KEY**\"\n",
    "\n",
    "Replace \"YOUR API KEY\" below with what you copy from \"**YOUR API KEY**\" (N.B. you need to keep the quotation marks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your api key:\n",
    "api_key = \"cmJ1UGJQVzZnT09HU2RUWDJhTGFkOGY4RjhnYTpGRmFCTTNoSXluVk1NdEk4b2dPc2ZjMHFOdlVh\"\n",
    "# where the data should be downloaded to:\n",
    "download_dir_path = \"/home/jovyan/work/products\"\n",
    "# where we can find our data query form:\n",
    "JSON_query_dir = os.path.join(os.getcwd(),'JSON_templates')\n",
    "# HDA-API loud and noisy?\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data source (which we use as a key for our JSON query file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMEMS OSTIA SST KEY\n",
    "dataset_id = \"EO:MO:DAT:SST_GLO_SST_L4_REP_OBSERVATIONS_010_011\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our date requirements. We do this year by year so we can choose a given month if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = []\n",
    "end_dates = []\n",
    "for ii in range(1988,2007+1):\n",
    "    start_dates.append(str(ii)+\"-01-01T00:00:00.000Z\")\n",
    "    end_dates.append(str(ii)+\"-12-31T00:00:00.000Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our data source to load the correct JSON query file from ../JSON_templates. (This is just my convention for building queries, there are many other ways you could do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find query file\n",
    "JSON_query_file = os.path.join(JSON_query_dir,dataset_id.replace(':','_')+\".json\")\n",
    "if not os.path.exists(JSON_query_file):\n",
    "    print('Query file ' + JSON_query_file + ' does not exist')\n",
    "else:\n",
    "    print('Found JSON query file for '+dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download the data. See the following scripts and notebooks for information on how this works:\n",
    "    \n",
    "    *samples/How_To_Guide-Harmonized_Data_Access-v0.1.3.ipynb*\n",
    "    *ocean-wekeo-jpyhub/HDA_API_Tools/HDA_API_downloading.ipynb*\n",
    "    *ocean-wekeo-jpyhub/Hub_Tools/harmonised_data_access_api_tools.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HAPI_dict = hapi.init(dataset_id, api_key, download_dir_path, verbose=verbose)\n",
    "HAPI_dict = hapi.get_access_token(HAPI_dict)\n",
    "HAPI_dict = hapi.accept_TandC(HAPI_dict)\n",
    "\n",
    "for start_date, end_date in zip(start_dates, end_dates):\n",
    "    print('Running for: ' + start_date + ' to ' + end_date)\n",
    "\n",
    "    date_string = start_date.split('T')[0].replace('-','') \\\n",
    "                  + '_' + end_date.split('T')[0].replace('-','')\n",
    "    \n",
    "    # load the query\n",
    "    with open(JSON_query_file, 'r') as f:\n",
    "        query = f.read()\n",
    "        query = query.replace(\"%DATE_START%\",start_date)\n",
    "        query = query.replace(\"%DATE_END%\",end_date)\n",
    "        query = json.loads(query)\n",
    "    \n",
    "    # launch job\n",
    "    HAPI_dict = hapi.launch_query(HAPI_dict, query)\n",
    "\n",
    "    # wait for jobs to complete\n",
    "    HAPI_dict = hapi.check_job_status(HAPI_dict)\n",
    "    if HAPI_dict['nresults'] == 0:\n",
    "        print('Nothing to do for this query....')\n",
    "        continue\n",
    "\n",
    "    # check results\n",
    "    HAPI_dict = hapi.get_results_list(HAPI_dict)\n",
    "    HAPI_dict = hapi.get_download_links(HAPI_dict)\n",
    "\n",
    "    # check prospective filenames:\n",
    "    HAPI_dict = hapi.get_filenames(HAPI_dict)\n",
    "    \n",
    "    # we are going to rename files are the downloaded format is not very useful...\n",
    "    Downloaded_file = HAPI_dict['filenames'][0].split('_')[0] \\\n",
    "                      + '_' + date_string + '.nc'\n",
    "    print('Will save file as: ' + Downloaded_file)\n",
    "\n",
    "    # download data\n",
    "    if os.path.exists(Downloaded_file):\n",
    "        print('File already exists')\n",
    "    else:\n",
    "        HAPI_dict = hapi.download_data(HAPI_dict, skip_existing=True)\n",
    "        os.rename(HAPI_dict['filenames'][0],Downloaded_file)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
