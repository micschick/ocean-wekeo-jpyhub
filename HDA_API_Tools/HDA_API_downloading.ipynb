{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonised API examples for downloading EUM / ESA / CMEMS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Version: 1.0\n",
    "    Date:    27/09/2019\n",
    "    Author:  Ben Loveday (Plymouth Marine Laboratory) and Hayley Evers-King (EUMETSAT)\n",
    "    Credit:  This code was developed for EUMETSAT under contracts for the Copernicus \n",
    "             programme.\n",
    "    License: This code is offered as open source and free-to-use in the public domain, \n",
    "             with no warranty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is this notebook for?**\n",
    "\n",
    "This script shows you some examples of how to download data from different sources using the harmonised data access API (HDA-API). The companion script *samples/How_To_Guide-Harmonized_Data_Access-v0.1.3.ipynb* shows how this works more explicitly, but for general use we have refactored the code into a series of functions that can be found here *ocean-wekeo-jpyhub/Hub_Tools/harmonised_data_access_api_tools.py*.\n",
    "\n",
    "\n",
    "**What specific tools does this notebook use?**\n",
    "\n",
    "The harmonised data access API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is divided into a series of modules that each contain a series of methods for specific tasks. The box below imports all of the modules we need to complete this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "sys.path.append(os.path.dirname(os.getcwd()) + '/Hub_Tools/')\n",
    "import harmonised_data_access_api_tools as hapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEkEO provides access to a huge number of datasets through its 'harmonised-data-access' API. This allows us to query the full data catalogue and download data quickly and directly onto our Jupyter Hub. You can search for what data is available here: https://www.wekeo.eu/dataset-navigator/start.\n",
    "\n",
    "In order to use the HDA-API we need to provide some authentication credentials, which comes in the form of an api_key. You can get your key from here; https://www.wekeo.eu/api-keys. If you click on the 'show hidden keys' button at the bottom of the page it will reveal a number of keys. The one you need is in the top grey box, and is on the following line:\n",
    "\n",
    "-H \"Authorization: Basic \"**YOUR API KEY**\"\n",
    "\n",
    "Replace \"YOUR API KEY\" below with what you copy from \"**YOUR API KEY**\" (N.B. you need to keep the quotation marks.)\n",
    "\n",
    "We will also define a few other parameters including where to download the data to, and if we want the HDA-API functions to be verbose. **Lastly, we will tell the notebook where to find the query we will use to find the data.** These 'JSON' queries are what we use to ask WEkEO for data. They have a very specific form, but allow us quite fine grained control over what data to get. You can find the example one that we will use here: **JSON_templates/RGB/EO_EUM_DAT_SENTINEL-3_OL_1_EFR___.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"YOUR API KEY\"\n",
    "download_dir_path = \"/home/jovyan/work/products\"\n",
    "JSON_query_dir = os.path.join(os.getcwd(),'JSON_templates')\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a timer going so we can see how long a test download takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each WEkEO hosted data set has a unique identifier. A number of these are show below as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data sets available: codes from here >> https://www.wekeo.eu/dataset-navigator/start\n",
    "\n",
    "# ---------------------------- CMEMS options --------------------------\n",
    "#dataset_id = \"EO:MO:DAT:SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001\" # CMEMS SEA-ICE\n",
    "#dataset_id = \"EO:MO:DAT:OCEANCOLOUR_GLO_CHL_L4_REP_OBSERVATIONS_009_093\" # CMEMS OC-CCI CHL\n",
    "dataset_id = \"EO:MO:DAT:SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001\" # CMEMS OSTIA SST\n",
    "\n",
    "# ---------------------------- C3S options ----------------------------\n",
    "#dataset_id = \"EO:ECMWF:DAT:ERA5_HOURLY_DATA_ON_SINGLE_LEVELS_1979_PRESENT\" # ERA5\n",
    "\n",
    "# ---------------------------- CAMS options ---------------------------\n",
    "#dataset_id = \"EO:ECMWF:DAT:CAMS_SOLAR_RADIATION_TIMESERIES\" # SOLAR RAD\n",
    "\n",
    "# ----------------- EUMETSAT COPERNICUS MARINE options ----------------\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:SR_1_SRA___\" # SRAL L1B\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:SR_1_SRA_BS___\" #SRAL L1BS\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:SR_2_WAT___\" # SRAL L2\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:OL_1_ERR___\" # OLCI ERR\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:OL_1_EFR___\" # OLCI EFR\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:OL_2_WRR___\" # OLCI WRR\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:OL_2_WFR___\" # OLCI WFR\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:SL_1_RBT___\" # SLSTR L1 RBT\n",
    "#dataset_id = \"EO:EUM:DAT:SENTINEL-3:SL_2_WST___\" # SLSTR L2 WST\n",
    "\n",
    "# ------------------------- EUMETSAT other options -------------------\n",
    "#dataset_id = \"EO:EUM:SV:EUMETSAT:V01\"\n",
    "                \n",
    "# ------------------------- ESA MARINE options ------------------------\n",
    "#dataset_id = \"EO:ESA:DAT:SENTINEL-2:MSI1C\"       # MSI L1C tested\n",
    "#dataset_id = \"EO:ESA:DAT:SENTINEL-1:L1_GRD\"      # S1 L1 GRD tested\n",
    "#dataset_id = \"EO:ESA:DAT:SENTINEL-1:L1_SLC\"      # S1 L1 SLC tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the data we need to construct a JSON query to send to the WEkEO data server via the harmonised data access API. There are a number of ways to do this, but to facilitate easy construction and editing of the query, we have chosen to make a them as text files. The *../JSON_templates/* directory contains examples for all of the examples above. By default, we use an adaptation of the *dataset_id* (\"colon\" replaced with \"underscore\" with a .json extension) to refer to the relevant query file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find query file\n",
    "JSON_query_file = os.path.join(JSON_query_dir,dataset_id.replace(':','_')+\".json\")\n",
    "if not os.path.exists(JSON_query_file):\n",
    "    print('Query file ' + JSON_query_file + ' does not exist')\n",
    "    print('Script will stop after showing metadata, to aid in creating a query file.')\n",
    "    need_meta = True\n",
    "else:\n",
    "    print('Found JSON query file, you may want to adapt it.')\n",
    "    need_meta = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our query file, we can get our data. You can find more detailed information in *samples/How_To_Guide-Harmonized_Data_Access-v0.1.3.ipynb*. We proceed as follows:\n",
    "\n",
    "    i)   initialise a dictionary to hold all of our API variables.\n",
    "    ii)  use our API key to get an access token for our data request\n",
    "    iii) accept the WEkEO terms and conditions\n",
    "    iv)  optionally print out meta data associated with dataset_id (this is very useful for creating queries).\n",
    "    v)   load the query file into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i) initialise\n",
    "HAPI_dict = hapi.init(dataset_id, api_key, download_dir_path, verbose=verbose)\n",
    "# ii) get token\n",
    "HAPI_dict = hapi.get_access_token(HAPI_dict)\n",
    "# iii) accept T&C\n",
    "HAPI_dict = hapi.accept_TandC(HAPI_dict)\n",
    "# iv) check meta data for the dataset product >> query generation\n",
    "if need_meta:\n",
    "    HAPI_dict = hapi.query_metadata(HAPI_dict)\n",
    "    sys.exit()\n",
    "# v) load the query\n",
    "with open(JSON_query_file, 'r') as f:\n",
    "    query = json.load(f)\n",
    "\n",
    "print('--------------------------------')\n",
    "print('Elapsed time: %s' % (time.time() - t0))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can launch our query and get our data:\n",
    "\n",
    "    vi)   launch the query, which will prepare our data\n",
    "    vii)  wait for the data preparation to complete\n",
    "    viii) get our list of results\n",
    "    ix)   get our download links\n",
    "    x)    download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi) launch job\n",
    "HAPI_dict = hapi.launch_query(HAPI_dict, query)\n",
    "# vii) wait for jobs to complete\n",
    "hapi.check_job_status(HAPI_dict)\n",
    "# viii) get the query results\n",
    "HAPI_dict = hapi.get_results_list(HAPI_dict)\n",
    "# ix) get the download links\n",
    "HAPI_dict = hapi.get_download_links(HAPI_dict)\n",
    "# x) download data\n",
    "HAPI_dict = hapi.download_data(HAPI_dict, skip_existing=True)\n",
    "\n",
    "print('--------------------------------')\n",
    "print('Elapsed time: %s' % (time.time() - t0))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done! Your data product should now be downloaded to the specified download path (*download_dir_path*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
